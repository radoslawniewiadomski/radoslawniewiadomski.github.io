<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html>
 <head>

  <title>Radoslaw Niewiadomski</title>
	<meta name="robots" content="follow,index">
	<meta name="Keywords" content="Radoslaw Niewiadomski, Niewiadomski, eca, affect, emotion, informatyka afektywna, greta, multimodal, multimedialny, agent, affective computing, avatar, awatar, nonverbal communication, komunikacja nonwerbalna, virtual agents, expressivity, multimodal, humanoid, emotions, expressions, multimedia, signal social processing, laughter, detection, recognition, multimodal, personality, nonverbal, karate, respiration, recognition, nonverbal, dance, ssp, social, touch">

  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <link rel="stylesheet" href="news_scroll.css" type="text/css">
  <link rel="stylesheet" type="text/css"  href="style.css" media="screen"/>
  
<body>

<div id="container">
<div id="navcontainer">
<ul id="navlist">
<li><a href="index.html">Home</a></li>
<li><a href="research.html">Research</a></li>
<li><a href="papers.html">Publications</a></li>
<li><a href="others.html">Datasets</a></li>
<li><a href="#"></a></li>
</ul>
</div>

<h1>Rados≈Çaw Niewiadomski</h1> 
<table border=0><tr VALIGN="top">
<td width="230">
<br>
<br>
<br>
<img src="radek.jpg" width="230">
</td>
<td width="100">
 
</td>
<td width="500">
<p id="content2">
<a href="https://rubrica.unige.it/personale/UkNFU1xt">Tenure-Track Assistant Professor</a> at the <a href="https://unige.it">University of Genoa</a> and 
 Affiliated Reseacher at <a href="https://www.iit.it"> Istituto Italiano di Tecnologia</a>.
<br>
<br>
Founder of <a href="happilab/happilab.html">hAppI Lab</a>, aiming to study and design technology capable of creating
novel Affective Interactions.
<br>
<br>
My research interests include: emotion recognition, social signal processing,  interactive multimodal systems, nonverbal behavior synthesis, embodied conversational agents and social robots. 
<p id="content7">
News and Updates:  <a href="https://www.linkedin.com/in/radoslaw-niewiadomski-b40522a/">LinkedIn</a>  and
 <a href="https://bsky.app/profile/happilab.bsky.social">BlueSky</a> 
</p>
</td>
</tr>
</table>

<table border=0><tr VALIGN="top"><td>
<div id="content">
I obtained my Ph.D. in 2007 from the University of Perugia. My dissertation, titled "A Model of Complex Facial Expressions in Interpersonal Relations," presented an application of fuzzy methods to the generation of facial expressions in virtual agents. For more details, see <a href="papers/IJHCS10_niewiadomskietal_draft.pdf">here</a>.
<br>
<br>
As a postdoctoral researcher, I worked in the LINC lab at the University Paris 8 and in the <a href="http://www.tsi.telecom-paristech.fr/mm/en/">Multimedia Group</a> at Telecom ParisTech, contributing to several research projects such as FP7 ILHAIRE, <a href="https://cordis.europa.eu/project/id/231287">FP7 SSPNET</a>, <a href="http://www.callas-newmedia.eu">FP6 CALLAS</a>, and French ANR project CECIL. My research focused on modeling expressive behaviors in virtual agents. I also contributed to the development of the Embodied Conversational Agent called <a href="https://github.com/gretaproject/greta">Greta</a>. You can learn more about <a href="papers/WEB3d11_niewiadomskietal.pdf">here</a>.
<br>
<br>
I also worked at the <a href="http://www.infomus.org">InfoMus Lab</a> at the University of Genoa, where I focused on the analysis and recognition of full-body expressive behaviors. I served as the Work Package Leader of the H2020 ICT <a href="http://dance.dibris.unige.it/">DANCE</a> Project, which aimed to analyze and sonify the expressive movement qualities in dance. I was also involved in the FP7 FET <a href="https://cordis.europa.eu/project/id/270780">ILHAIRE</a> Project, focused on the analysis and synthesis of multimodal laughter, as well as the H2020 <a href="https://www.wedraw.eu/"> WeDraw </a> and H2020 <a href="http://www.wholodance.eu/"> WhoLoDancE</a>.
<br>
<br>
I contributed to the creation of several freely available datasets, including <a href="http://www.infomus.org/ILHAIRE/mmli/">full-body laughter expressions (MMLI)</a>, <a href="http://www.infomus.org/karate/eyesweb_dataset_karate_eng.php">kata (karate) performances</a>, <a href="http://dance.dibris.unige.it/index.php/dance-datasets/expressive-vocabulary-data">expressive movement qualities in dance</a>. As a Guest Editor, I proposed the Special Section dedicated to <a href="https://ieeexplore.ieee.org/document/8119741">laughter computing</a> in IEEE Transactions on Affective Computing, and the Reseach Topic on <a href="https://www.frontiersin.org/research-topics/15476/computational-commensality">
Computational Commensality</a> in Frontiers.
<br>
<p id="content7">
Read more about our recent projects <a href="./happilab/projects.html">here</a>.
<br>
Check the list of <a href="https://github.com/radoslawniewiadomski/happilab/tree/main/topics">Master thesis and/or interships</a>.</p>
<br>
<p id="content17">
Visit my profiles on: 
<a href="http://scholar.google.com/citations?user=CcrCL8cAAAAJ&hl">Google Scholar</a>, 
<a href="http://www.researchgate.net/profile/Radoslaw_Niewiadomski/">ResearchGate</a>, 
<a href="http://www.scopus.com/authid/detail.url?authorId=55911729200">SCOPUS</a>,
<a href="http://orcid.org/0000-0002-0476-0803">ORCID</a>, 
<a href="https://www.webofscience.com/wos/author/record/D-9775-2015">WoS</a>, 
<a href="https://www.linkedin.com/in/radoslaw-niewiadomski-b40522a/">LinkedIn</a> 
and 
<a href="https://www.youtube.com/embed/videoseries?list=PLmvhgYxJwm8FrG3pOJVA4TBV0ssVbg7KX">Youtube playlist</a>.
</p>
<br>
</td>
</tr>
</table>
email: <i> {firstname}.{lastname}{at} dibris {.} unige {.it} 
</div>
</div>
</body>
</html>
