
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html>
 <head>

  <title>Radoslaw Niewiadomski</title>
	<meta name="robots" content="follow,index">
	<meta name="Keywords" content="Radoslaw Niewiadomski, Niewiadomski, eca, affect, emotion, informatyka afektywna, greta, multimodal, multimedialny, agent, affective computing, avatar, awatar, nonverbal communication, komunikacja nonwerbalna, virtual agents, expressivity, multimodal, humanoid, emotions, expressions, multimedia, signal social processing, laughter, detection, recognition, multimodal, personality, nonverbal, karate, respiration, recognition, nonverbal, dance, ssp, social, touch">

  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <link rel="stylesheet" href="news_scroll.css" type="text/css">
  <link rel="stylesheet" type="text/css"  href="style.css" media="screen"/>
  
<body>

<div id="container">
<div id="navcontainer">
<ul id="navlist">
<li><a href="index.html">Home</a></li>
<li><a href="research.html">Research</a></li>
<li><a href="papers.html">Publications</a></li>
<li><a href="others.html">Datasets</a></li>
<li><a href="#"></a></li>
</ul>
</div>


<h1>Rados≈Çaw Niewiadomski</h1> 
<table border=0><tr VALIGN="top">
<td width="230">
<img src="radek.jpg" width="230">
</td>

<td width="30">
</td>

<td width="500">
<p id="content2">
<a href="https://rubrica.unige.it/personale/UkNFU1xt">Tenure-Track Assistant Professor</a> at the <a href="https://unige.it">University of Genoa</a> and 
 Affiliated Reseacher at <a href="https://www.iit.it"> Istituto Italiano di Tecnologia</a>.
<br>
<br>
founder of <a href="happilab/happilab.html">hAppI Lab</a>, aiming to study and design technology capable of creating
novel Affective Interactions.
<br>
<br>
<br>
My research interests include: emotion recognition, social signal processing,  interactive multimodal systems, nonverbal behavior synthesis, embodied conversational agents and social robots. 
<br>
</td>
</tr>
</table>
</br>

<p id="content7">
Check the list of <a href="new_topics.pdf">Master thesis and/or interships</a> at the University of Genoa<br></p>

<div id="news_iframe_scroll">
<div class="news_scroll-title">News and Updates<br></div>
<iframe name="NewsIFrame" src="news_scroll.html" frameborder="0" scrolling="no"></iframe>
</div>


<table border=0><tr VALIGN="top"><td>
<div id="content">
I obtained my Ph.D. in 2007 from the University of Perugia. My dissertation, titled "A Model of Complex Facial Expressions in Interpersonal Relations," presented an application of fuzzy methods to the generation of facial expressions in virtual agents. For more details, see <a href="papers/IJHCS10_niewiadomskietal_draft.pdf">here</a>.
<br>
<br>
As a postdoctoral researcher, I worked in the LINC lab at the University Paris 8 and in the <a href="http://www.tsi.telecom-paristech.fr/mm/en/">Multimedia Group</a> at Telecom ParisTech, contributing to several research projects such as FP7 ILHAIRE, <a href="https://cordis.europa.eu/project/id/231287">FP7 SSPNET</a>, <a href="http://www.callas-newmedia.eu">FP6 CALLAS</a>, and French ANR project CECIL. My research focused on modeling expressive behaviors in virtual agents. I also contributed to the development of the Embodied Conversational Agent called <a href="https://github.com/gretaproject/greta">Greta</a>. You can learn more about <a href="papers/WEB3d11_niewiadomskietal.pdf">here</a>.
<br>
<br>
I also worked at the <a href="http://www.infomus.org">InfoMus Lab</a> at the University of Genoa, where I focused on the analysis and recognition of full-body expressive behaviors. I served as the Work Package Leader of the H2020 ICT <a href="http://dance.dibris.unige.it/">DANCE</a> Project, which aimed to analyze and sonify the expressive movement qualities in dance. I was also involved in the FP7 FET <a href="https://cordis.europa.eu/project/id/270780">ILHAIRE</a> Project, focused on the analysis and synthesis of multimodal laughter, as well as the H2020 <a href="https://www.wedraw.eu/"> WeDraw </a> and H2020 <a href="http://www.wholodance.eu/"> WhoLoDancE</a>.
<br>
<br>
Furthermore, I contributed to the creation of several freely available datasets, including <a href="http://www.infomus.org/ILHAIRE/mmli/">full-body laughter expressions (MMLI)</a>, <a href="http://www.infomus.org/karate/eyesweb_dataset_karate_eng.php">kata (karate) performances</a>, <a href="http://dance.dibris.unige.it/index.php/dance-datasets/expressive-vocabulary-data">expressive movement qualities in dance</a>. As a Guest Editor, I proposed the Special Section dedicated to <a href="https://ieeexplore.ieee.org/document/8119741">laughter computing</a> in IEEE Transactions on Affective Computing, and the Reseach Topic on <a href="https://www.frontiersin.org/research-topics/15476/computational-commensality">
Computational Commensality</a> in Frontiers.
<br>
<br>
Visit my profile on: 
<a href="http://scholar.google.com/citations?user=CcrCL8cAAAAJ&hl">Google Scholar</a>, 
<a href="http://www.researchgate.net/profile/Radoslaw_Niewiadomski/">ResearchGate</a>, 
<a href="http://www.scopus.com/authid/detail.url?authorId=55911729200">SCOPUS</a>,
<a href="http://orcid.org/0000-0002-0476-0803">ORCID</a>, 
<a href="https://www.linkedin.com/in/radoslaw-niewiadomski-b40522a/">LinkedIn</a> 
and my 
<a href="https://www.youtube.com/embed/videoseries?list=PLmvhgYxJwm8FrG3pOJVA4TBV0ssVbg7KX">Youtube playlist</a>.
</p>
<br>
</td>
</tr>
</table>
email: <i> {firstname}.{lastname}{at} dibris {.} unige {.it} 
</div>
</body>
</html>
