<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html><head>

 
<title>Papers</title>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <link rel="stylesheet" type="text/css" href="style.css" media="screen">
  <meta name="robots" content="follow,index">  
</head><body>


<div id="container">
<div id="navcontainer">
<ul id="navlist">
<li><a href="index.html">Home</a></li>
<li><a href="research.html">Research</a></li>
<li><a href="papers.html">Publications</a></li>
<li><a href="others.html">Datasets</a></li>
</ul>
</div>

 

<div class="menu">
<ul>
<li><a href="#editorial">Editor</a></li>
<li><a href="#journal">Journal Papers</a></li>
<li><a href="#chapters">Book Chapters</a></li>
<li><a href="#conference">Conference Papers</a></li>
<li><a href="#others">Others</a></li>
</ul>
</div>	


<div id="content1">
<b><a name="editorial">Editor:</a></b>
<br><br>
<table border=0>
<tr VALIGN="top">
 
<td>E3</td>
<td>  
Mancini, M., Cavazza, N., Higgs, S., Huisman, G., Van Den Boer, J., <b>Niewiadomski, R.</b>, 
<a href="https://www.frontiersin.org/articles/10.3389/fcomp.2022.1086841/full">
Computational Commensality</a>, 
Frontiers in Computer Science.
<br>
<i>10.3389/fcomp.2022.1086841</i>
</td>
<td>
</td>
</tr>

<tr><td></td><td></td><td></td></tr>


<td>E2</td>
<td>  
Camurri, A., Volpe, V., Mancini, M., <b>Niewiadomski, R.</b>, Piana, S., 
<a href="https://portalparts.acm.org/3220000/3212721/fm/frontmatter.pdf">Proceedings of the 5th International Conference on Movement and Computing</a>, ACM Digital Library. 
<br>
ISBN 978-1-4503-6504-8.
</td>
<td>
<a href="https://radoslawniewiadomski.github.io/papers/moco2018_camurri.txt">[bibtex]</a>
</td>
</tr>
<tr><td></td><td></td><td></td></tr>

<tr>
<td>E1</td>
<td>  
Mancini, M., <b>Niewiadomski, R.</b>, Hashimoto, S., Foster, M.E., Scherer, S., Volpe, G., 
<a href="/papers/TAC17_mancinietal_draft.pdf">
Guest Editorial: Towards Machines Able to Deal with Laughter</a>, 
in IEEE Transactions on Affective Computing, Vol. 8, 2017.
<br>
<i>doi: 10.1109/TAFFC.2017.2766938</i>
</td>
<td>
<a href="https://radoslawniewiadomski.github.io/papers/tac2017_mancini.txt">[bibtex]</a>
<br>
<a href="http://ieeexplore.ieee.org/document/8119741/">[link]</a>
</td>
</tr>

<tr><td></td><td></td><td></td></tr>
</table>
<br><br>

<b><a name="journal">Journal Papers:</a></b>
<br><br>
<table border=0>

<tr VALIGN="top">
<td>IJ24</td>
<td>
Cinelli, M., Etta, G., Franzoni, V., Mancini, M., Niewiadomski, R.,
 From Polarization to Pro-Sociality: Measuring Beneficence in Controversial Online Conversations, 
IEEE Access, 2024
<br><i>10.1109/ACCESS.2023.1120000</i>
</td>
<td>
</tr>
<tr><td></td><td></td><td></td></tr>

	  
<td>IJ23</td>
<td>
Niewiadomski, R., Larradet, F., Barresi, G., Mattos, L.S.,
<a href="https://www.frontiersin.org/articles/10.3389/fcomp.2023.1285690">
Self-assessment of affect-related events for physiological data collection in the wild based on appraisal theories</a>, 
Frontiers in Computer Science, volume 5, 2024 
<br><i>10.3389/fcomp.2023.1285690</i>
</td>
<td>
</tr>
<tr><td></td><td></td><td></td></tr>


<td>IJ22</td>
<td>
Lechuga Redondo, M., <b>Niewiadomski, R.,</b>, Rea, F., Incao, S., Sandini, G., Sciutti, A.,
<a href="https://link.springer.com/article/10.1007/s12369-023-01026-9">
 Comfortability Analysis under a Human-robot Interaction Perspective</a>, 
International Journal of Social Robotics
<br><i>10.1007/s12369-023-01026-9</i>
</td>
<td>
</tr>
<tr><td></td><td></td><td></td></tr>


<td>IJ21</td>
<td>
D’incà, M., Beyan, C., <b>Niewiadomski, R.,</b>, Barattin, S., Sebe, N.,
<a href="https://ieeexplore.ieee.org/document/10227296">
Unleashing the Transferability Power of Unsupervised Pre-Training for Emotion Recognition in Masked and Unmasked Facial Images</a>,  
IEEE Access, 2023.
<br><i>10.1109/Access.2023.3308047</i>
</td>
<td>
</tr>
<tr><td></td><td></td><td></td></tr>


<td>IJ20</td>
<td>
<b>Niewiadomski, R.,</b>, Beyan, C., Sciutti, A.,
<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9992107">
Affect Recognition in Hand-Object Interaction Using Object-Sensed Tactile and Kinematic Data</a>,  
IEEE Transactions on Haptics, vol. 16, no. 1, pp. 112-117, 2023.
<br><i>10.1109/TOH.2022.3230643</i>
</td>
<td>
<a href="https://youtu.be/lEVe6Dq9CyA">[video]</a>
</tr>

<tr><td></td><td></td><td></td></tr>

<td>IJ19</td>
<td>
Ceccaldi, E., <b>Niewiadomski, R.</b>, R., Mancini, M., Volpe, G.,
<a href="https://www.frontiersin.org/articles/10.3389/fpsyg.2022.911000/full">
What's on your plate? Collecting multimodal data to understand commensal behavior</a>,  
Frontiers in Psychology, 13:911000, 2022. 
<br><i>doi: 10.3389/fpsyg.2022.911000</i>
</td>
<td>
</tr>

<tr><td></td><td></td><td></td></tr>

<td>IJ18</td>
<td>
<b>Niewiadomski, R.</b>,  Bruijnes, M., Huisman, G., Gallagher, C.P., Mancini, M.
<a href="https://www.frontiersin.org/articles/10.3389/fcomp.2022.909844/full">
Social robots as eating companions</a>, Frontiers in Computer Science, 4, 2022.
<br><i>doi: 10.3389/fcomp.2022.909844</i>
</td>
<td>
</td>
</tr>

<tr><td></td><td></td><td></td></tr>


<td>IJ17</td>
<td>
Beyan, C., Karumuri, S., Volpe, G., Camurri, A., <b>Niewiadomski, R.</b>,
<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9477164">Modeling Multiple Temporal Scales of Full-body Movements for Emotion Classification</a>,  
IEEE Transactions on Affective Computing (early access). 
<br><i>doi: 10.1109/TAFFC.2021.3095425</i>
</td>
<td>
<a href="https://youtu.be/xdoXDnOf0oI">[video]</a>
</td>
</tr>

<tr><td></td><td></td><td></td></tr>

<td>IJ16</td>
<td>

Larradet, F., <b>Niewiadomski, R.</b>, Barresi, G., Caldwell, D.G., Mattos, L.S.
<a href="https://www.frontiersin.org/articles/10.3389/fpsyg.2020.01111/full">
Toward Emotion Recognition From Physiological Signals in the Wild: Approaching the Methodological Issues in Real-Life Data Collection</a> 
Frontiers in Psychology, 11, 2020. 
<br><i>doi: 10.3389/fpsyg.2020.01111</i>
</td>
<td> <a href="/papers/Frontiers2020_larradetatal.txt">[bibtex]</a>
</td>
</tr>

<tr><td></td><td></td><td></td></tr>

<td>IJ15</td>
<td>
Olugbade, T., Newbold, J., Johnson, R. Volta, E., Alborno, P., <b>Niewiadomski, R.</b>, Dillon, M., Volpe, G., Berthouze, N., 
Automatic Detection of Reflective Thinking in Mathematical Problem Solving based on Unconstrained Bodily Exploration, 
IEEE Transactions on Affective Computing (early access).
<br><i>doi: 10.1109/TAFFC.2020.2978069</i>
</td>
<td>
<a href="/papers/TAC20_olugbadeetal.txt">[bibtex]</a>
<br>
<a href="https://ieeexplore.ieee.org/document/9037266">[link]</a>
</td>
</tr>

<tr><td></td><td></td><td></td></tr>

<td>IJ14</td>
<td>
<b>Niewiadomski, R.</b>, Ceccaldi, E., Huisman, G., Volpe, G., Mancini, M., 
<a href="https://www.frontiersin.org/articles/10.3389/frobt.2019.00119/full">
Computational Commensality: From Theories to Computational Models for Social Food Preparation and Consumption in HCI</a>, 
Frontiers in Robotics and AI, 6, 2019.
<br><i>doi: 10.3389/frobt.2019.00119</i>
</td>
<td>
<a href="/papers/Frontiers2019_niewiadomskiatal.txt">[bibtex]</a>
</td>
</tr>

<tr><td></td><td></td><td></td></tr>
<td>IJ13</td>
<td>
Lussu, V., <b>Niewiadomski, R.</b>, Volpe, G., Camurri, A.,
<a href="https://link.springer.com/content/pdf/10.1007/s12193-019-00302-1.pdf">
The role of respiration audio in multimodal analysis of movement qualities</a>, 
Journal on Multimodal User Interfaces, Volume 14, February 2020.
<br><i>doi: 10.1007/s12193-019-00302-1</i>
</td>
<td>
<a href="https://radoslawniewiadomski.github.io/papers/ijmui2019_lussuetal.txt">[bibtex]</a>
</td>
</tr>

<tr><td></td><td></td><td></td></tr>
<td>IJ12</td>
<td>
<b>Niewiadomski, R.</b>, Kolykhalova, K., Piana, S., Alborno, P., Volpe, G., Camurri, A., 
<a href="https://dl.acm.org/citation.cfm?id=3132369">
Analysis of Movement Quality in Full-Body Physical Activities</a>, 
ACM Transaction on Interactive Intelligent Systems, Volume 9 Issue 1, February 2019.
<br><i>doi: 10.1145/3132369</i>
</td>
<td>
<a href="/papers/TIIS19_niewiadomski_etal.txt">[bibtex]</a>
<br>
<a href="https://www.youtube.com/watch?v=bWd3aFDsdlg">[video]</a>
</td>
</tr>
<tr><td></td><td></td><td></td></tr>
<td>IJ11</td>
<td>
<b>Niewiadomski, R.</b>, Mancini, M., Cera, A., Piana, S., Canepa, C., Camurri, A., 
<a href="https://link.springer.com/content/pdf/10.1007%2Fs12193-018-0284-0.pdf">
Does embodied training improve the recognition of mid-level expressive movement qualities sonification?</a>, 
Journal on Multimodal User Interfaces, 2018. 
<br><i>doi: 10.1007/s12193-018-0284-0</i>
</td>
<td>
<a href="/papers/ijmui2018_niewiadomski_etal.txt">[bibtex]</a>
</td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr VALIGN="top">
<td>IJ10</td>
<td>
<b>Niewiadomski, R.</b>, Mancini, M., Varni, G., Volpe, G., Camurri, A., 
<a href="/papers/THMS16_niewiadomskietal_draft.pdf">
Automated Laughter Detection from Full-Body Movements</a>, 
IEEE Transactions on Human-Machine Systems, vol.46, no.1, pages 113-123, Feb. 2016. 
<br><i>doi: 10.1109/THMS.2015.2480843</i>
</td>
<td>
<a href="/papers/THMS16_niewiadomskietal_draft.txt">[bibtex]</a>
<br>
<a href="http://ieeexplore.ieee.org/xpl/articleDetails.jsp?reload=true&arnumber=7298420">[link]</a>
</td>
</tr>
<tr><td></td><td></td><td></td></tr>

<tr>
<td>IJ9</td>
<td>
Hofmann, J., Platt, T., Ruch, W., <b>Niewiadomski, R.</b>, Urbain, J., The influence of a virtual companion on amusement when watching funny film, Motivation and Emotion, Volume 39, Issue 3, pages 434-44, 2015. 
<br><i>doi: 10.1007/s11031-014-9461-y</i>
</td>
<td>
<a href="/papers/ME05_Hofmann_et_al.txt">[bibtex]</a>
<br>
<a href=http://link.springer.com/article/10.1007%2Fs11031-014-9461-y>[link]</a></td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>IJ8</td>
<td>
<b>Niewiadomski, R.</b>, Pelachaud., C., 
<a href="/papers/TAP15_niewiadomskietal_draft.pdf">
The Effect of Wrinkles, Presentation Mode and Intensity on the Perception of Facial Actions and Full Face Expressions of Laughter</a>, 
ACM Transactions on Applied Perception, Volume 12 Issue 1, 2015.  
<br><i>doi: 10.1145/2699255</i> 
</td>
<td>
<a href="/papers/ACMTAP_niewiadomskietal_2015.txt">[bibtex]</a>
<br>
<a href="http://dl.acm.org/citation.cfm?id=2699255">[link]</a>
</td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>IJ7</td>
<td>
Ruch, W.F., Platt, T., Hofmann, J., <b>Niewiadomski, R.</b>, Urbain, J., Mancini, M. Dupont, S., 
<a href="http://journal.frontiersin.org/article/10.3389/fnhum.2014.00928/full">
Gelotophobia and the Challenges of Implementing Laughter into Virtual Agents Interactions</a>,
Frontiers in Human Neuroscience 8:928, 2014.
<br><i>doi: 10.3389/fnhum.2014.00928 </i></br> 
</td>
<td>
<a href="/papers/Frontiers2014_ruchetal.txt">[bibtex]</a> 
<br>
</td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>IJ6</td>
<td>
Ochs, M., <b>Niewiadomski, R.</b>, Brunet, P., Pelachaud, C., 
<a href="/papers/CP12_ochsetal_draft.pdf">Smiling virtual agent in social context</a>, 
Cognitive Processing, Volume 13, Issue 2, pages 519-532, 2012. 
<br><i>doi: 10.1007/s10339-011-0424-x</i> 
</td>
<td><a href="/papers/CP2011_ochsetal.txt">[bibtex]</a> 
<br>
<a href="http://link.springer.com/article/10.1007%2Fs10339-011-0424-x">[link]</a></td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>IJ5</td>
<td>
Demeure, V., <b>Niewiadomski, R.</b>, Pelachaud, C., 
<a href="/papers/MIT11_demeureetal_draft.pdf"> How believability of virtual agent is related to warmth, competence, personification and embodiment?</a>, MIT Presence, Vol. 20, No. 5, pages 431-448, October 2011. 
<br><i>doi: 10.1162/PRES_a_00065</i> 
</td>
<td><a href="/papers/MIT2011_demeureetal.txt">[bibtex]</a>
<br>
<a href="http://www.mitpressjournals.org/doi/pdf/10.1162/PRES_a_00065">[link]</a></td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>IJ4</td>
<td>
<b>Niewiadomski, R.</b>, Hyniewska, S, Pelachaud, C., 
<a href="/papers/TAC11_niewiadomskietal_draft.pdf">Constraint-Based Model for Synthesis of Multimodal Sequential Expressions of Emotions</a>, 
IEEE Transactions on Affective Computing, vol. 2, no. 3, pages 134-146, 2011. 
<br><i> doi: 10.1109/T-AFFC.2011.5 </i>  
</td>
<td>
<a href="/papers/tac2011_niewiadomski_etal.txt">[bibtex]</a>
<br>
<a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5740835&amp;tag=1">[link]</a>
</td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>IJ3</td>
<td>
Urbain, J., <b>Niewiadomski, R.</b>, Bevacqua, E., Dutoit, T., Moinet, A., Pelachaud, C., Picart, B., Tilmanne, J.,
Wagner, J., 
<a href="/papers/JMUI10_urbainetaldraft.pdf"> AVLaughterCycle. Enabling a virtual agent to join in laughing with a conversational partner using a similarity-driven audiovisual laughter animation</a>, 
Journal of Multimodal User Interfaces, vol. 4, n. 1, pages 47-58, 2010. 
<br><i> doi: 10.1007/s12193-010-0053-1 </i>
</td>
<td>
<a href="/papers/ijmui2010_urbainetal.txt">[bibtex]</a> 
<br>
<a href="http://link.springer.com/article/10.1007%2Fs12193-010-0053-1">[link]</a>
</td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>IJ2</td>
<td>
<b>Niewiadomski, R.</b>, Pelachaud, C.,
<a href="/papers/IJHCS10_niewiadomskietal_draft.pdf">
Affect expression in ECAs: Application to politeness displays</a>,
International Journal of Human-Computer Studies, 68, pages 851-871, 2010. 
<br><i> doi: 10.1016/j.ijhcs.2010.07.004 </i>
</td>
<td>
<a href="/papers/ijhcs2010_niewiadomskietal.txt">[bibtex]</a> 
<br>
<a href="http://www.sciencedirect.com/science/article/pii/S1071581910000893">[link]</a>
</td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>IJ1</td>
<td>Martin, J.-C., <b>Niewiadomski, R.</b>, Devillers, L., Buisine, S., Pelachaud, C.,
<a href="/papers/IJHR06_martinetal_draft.pdf"> 
Multimodal complex emotions: Gesture expressivity and blended facial expressions</a>,
International Journal of Humanoid Robotics, Special Edition "Achieving Human-Like Qualities in Interactive Virtual and Physical Humanoids", 
vol. 3, pages 269-292, 2006. 
<br><i> doi: 10.1142/S0219843606000825 </i>
</td><td>
<a href="/papers/ijhr2006_martinetal.txt">[bibtex]</a> 
<br>
<a href="http://www.worldscientific.com/doi/abs/10.1142/S0219843606000825">[link]</a>
</td>
</tr>
</table>

<br><br><br>
<b><a name="njournal">National Journal Papers:</a></b>
<br><br>
<table border=0><tr VALIGN="top">
<td>NJ2</td>
<td>de Sevin, E., <b>Niewiadomski, R.</b>, Bevacqua, E., Pez, A.-M., Mancini, M., 
Pelachaud, C.,  <a href="/papers/TSI10_desevinetal.pdf"> Greta, une plateforme d'agent conversationnel 
expressif et interactif</a>, Technique et science informatiques, le numéro spécial "Agents conversationnels animés", (vol. 29), pages 751-776, 2010. 
<br>
<i>doi: 10.3166/tsi.29.751-776</i>
</td><td>
<a href="https://tsi.revuesonline.com/article.jsp?articleId=15132">[link]</a>
</td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>NJ1</td>
<td>
Ochs, M., <b>Niewiadomski, R.</b>, Pelachaud, C., Sadek, D., <a href="/papers/RIA06_ochsetal_draft.pdf">Expressions Intelligentes des Emotions</a>, Revue en Intelligence Artificielle RIA,  
Special Edition “Interaction Emotionnelle”, vol. 20, N. 4-5, pages 198-221, 2006.
<br>
<i>doi: 10.3166/ria.20.607-620</i>
</td>
<td>
<a href="https://ria.revuesonline.com/article.jsp?articleId=8791">[link]</a>
</td>
</tr>
</table>

<br><br><br>
<b><a name="chapters">Book Chapters:</a></b>

<br><br>
<table border=0>
<tr VALIGN="top">
<td>BC12</td>
<td>
Ochs, M., <b>Niewiadomski, R.</b>, Pelachaud, C., 
<a href="/papers/BC12_ochsetal_draft.pdf">
Facial expressions of emotions for virtual characters
</a>, in: Calvo, R.A., D’Mello, S.K., Gratch, J., Kappas, A. (eds.), The Oxford Handbook of Affective Computing, pages 261-272, Oxford University Press, 2015.
<br>
<i>doi: 10.1093/oxfordhb/9780199942237.013.028</i>
</td>
<td>
<a href="/papers/ACIIHandbookOchs_etal.txt">[bibtex]</a> 
<br>
<a href="http://www.oxfordhandbooks.com/view/10.1093/oxfordhb/9780199942237.001.0001/oxfordhb-9780199942237-e-028">[link]</a>
</td>
</tr>

<tr>
<td>BC11</td>
<td>
Mancini, M., Ach, L., Bantegnie, E., Baur, T., Berthouze, N., Datta, D., Ding, Y., Dupont. S., Griffin, H.J., Lingenfelser, F., <b>Niewiadomski, R.</b>, Pelachaud, C., Pietquin, O., Piot, B., Urbain, J., Volpe, G., Wagner, J., Laugh When You're Winning, Advances in Information and Communication Technology 6102, Springer International Publishing. 2013.
<br>
<i>doi: 10.1007/978-3-642-55143-7_3</i>
</td>
<td>
<a href="/papers/SpringerMancinietal_2013.txt">[bibtex]</a> 
<br>
<a href="https://link.springer.com/chapter/10.1007/978-3-642-55143-7_3">[link]</a>
</td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>BC10</td>
<td>
<b>Niewiadomski, R.</b>, Mancini, M., Piana, S., 
<a href="/papers/BC10_niewiadomskietal_draft.pdf">
Human and virtual agent  expressive gesture quality analysis and synthesis</a>, Rojc, M., Campbell, N. (eds.) Coverbal Synchrony in Human-Machine Interaction, 
CRC Press, Science Publishers (USA), pages 269-292, 2013. 
<br>
<i>doi: 10.1201/b15477-14</i>
</td>
<td>
<a href="/papers/coverbal2013_niewiadomskietal.txt">[bibtex]</a>
<br>
<a href="http://www.crcpress.com/product/isbn/9781466598256">[link]</a>
</td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>BC9</td>
<td>
<b>Niewiadomski, R.</b>, Hyniewska, S., Pelachaud, C., 
<a href="/papers/BC09_niewiadomskietal_draft.pdf"> 
Computational Models of  Expressive Behaviors for a Virtual Agent</a>, in: Gratch, J., Marsella, S. (eds.) Social emotions in nature and artifact: Emotions in human and human-computer interaction, Oxford University Press, pages 143-157, 2013.
<br>
<i>doi: 10.1093/acprof:oso/9780195387643.003.0010</i>
</td>
<td><a href="http://ukcatalogue.oup.com/product/9780195387643.do">[link]</a></td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>BC8</td>
<td>
Ochs, M., Bevacqua, E., Prepin, K., Le, Q.A., Ding, Y., Huang, J.-F.,  <b>Niewiadomski, R.</b>, Pelachaud, C., La compréhension de la machine à 
travers l'expression non-verbale, in: Grandgeorge, M., Le  Pévédic, B., Pugnière-Saavedra, F. (eds.) Intercompréhensions comparées 
dans trois types d’interactions: Homme-Homme, Animal-Homme-Machine et Homme-Machine, E.M.E. Editions.
</td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>BC7</td>
<td>
Hyniewska, S., <b>Niewiadomski, R.</b>, Pelachaud, C., Modeling Facial Expressions of Emotions, C. Pelachaud (ed.) Emotion-oriented Systems, 
Wiley, pages 169-190, 2011. (French version: Hyniewska, S., <b>Niewiadomski, R.</b>, Pelachaud, C., 
<a href="/papers/BC07_hyniewskaetal_draft_fr.pdf"> 
Modélisation des expressions faciales des émotions</a>, 
C. Pelachaud (ed.) Systèmes d’Interaction Emotionnelle, Paris: Hermes Science, pages 201-222, 2010.)
<br>
<i>doi: 10.1002/9781118601938.ch6</i>
</td>
<td>
<a href="/papers/Emotion_Hyniewskaetal.txt">[bibtex]</a>
<br>
<a href="http://onlinelibrary.wiley.com/book/10.1002/9781118601938">[link]</a>
</td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>BC6
</td>
<td>
Martin, J-C, Devillers, L., Raouzaiou, A., Caridakis, G., Ruttkay, Z.,  Pelachaud, C., Mancini, M., <b>Niewiadomski, R.</b>, Pirker H., Krenn, B. et 
al., Coordinating the Generation of Signs in Multiple Modalities in an Affective Agent, R. Cowie, P. Petta, C. Pelachaud (eds.), 
Emotion-oriented Systems: Humaine Handbook, Part 4,  Springer, pages  349-367, 2011.
<br>
<i>doi:	10.1007/978-3-642-15184-2_18</i>
</td>
<td>
<a href="http://www.springer.com/computer/ai/book/978-3-642-15183-5">[link]</a>
</td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>BC5
</td>
<td>
André, E., Bevacqua, E., Heylen, D., <b>Niewiadomski, R.</b>, Poggi, I.,  Pelachaud, C., Peters, C., Rehm, M., 
Non-verbal persuasion and communication in an affective agent, R. Cowie,  P. Petta, C. Pelachaud (eds.), Emotion-oriented Systems: Humaine 
Handbook, Springer, pages 585-608, 2011.
<br>
<i>doi: 10.1007/978-3-642-15184-2_30</i>
</td>
<td><a href="http://www.springer.com/computer/ai/book/978-3-642-15183-5">[link]</a></td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>BC4
</td>
<td>
<b>Niewiadomski, R.</b>, Mancini, M., Hyniewska, S., Pelachaud, C., 
<a href="/papers/blueprint10_niewiadomskietal_draft.pdf">
Communicating emotional states with the Greta agent</a>,
Scherer, K.R., Banziger, T., Roesch, E. (eds.) A Blueprint for Affective Computing: A sourcebook, Oxford: Oxford University Press, pages 256-268, 2010.
<td>
<a href="/papers/blueprint2010_niewiadomskietal.txt">[bibtex]</a>
<br>
<a href="http://ukcatalogue.oup.com/product/9780199566709.do">[link]</a>
</td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>BC3
</td>
<td>
Hyniewska, S., <b>Niewiadomski, R.</b>, Mancini, M.,  Pelachaud, C., 
<a href="/papers/blueprint10_hyniewskaetal_draft.pdf">Expression of affects in Embodied Conversational Agents</a>, 
Scherer, K.R., Banziger, T., Roesch, E. (eds.) 
A Blueprint for Affective Computing: A sourcebook, Oxford: Oxford University Press, pages 213-221, 2010.
</td>
<td>
<a href="/papers/blueprint2010_hyniewskaetal.txt">[bibtex]</a>
<br>
<a href="http://ukcatalogue.oup.com/product/9780199566709.do">[link]</a>
</td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>BC2
</td>
<td>
Bevacqua, E., Prepin, K., <b>Niewiadomski, R.</b>, de Sevin, E., Pelachaud, C., <a href="/papers/BC02_bevacquaetal_draft.pdf">Greta: Towards an Interactive Conversational Virtual Companion</a>, 
Wilks Y.(ed.), Close Engagements with Artificial Companions: Key social, psychological, ethical and deisgn issues, John Benjamins Publishing 
Company, pages 143-156, 2010.
<br>
<i>doi: 10.1075/nlp.8.20bev</i>
</td>
<td>
<a href="http://benjamins.com/#catalog/books/nlp.8/main">[link]</a>
</td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>BC1
</td>
<td>
Poggi, I., <b>Niewiadomski, R.</b>, Pelachaud, C., <a href="/papers/BC01_poggietal_draft.pdf">Facial Deception in Humans and ECAs</a>,
Wachsmuth, I., Knoblich, G. (eds.), Modeling Communication for Robots and Virtual Humans, 
Springer, pages 198-221, 2008. 
<br>
<i>doi: 10.1007/978-3-540-79037-2_11</i>
</td>
<td>
<a href="/papers/modeling2008_poggietal.txt">[bibtex]</a><a href="http://link.springer.com/book/10.1007%2F978-3-540-79037-2">[link]</a>
</td>
</tr>
</table>
<br><br><br>

<b><a name="conference">International Conference and Workshop Papers:</a></b>
<table border=0>

<tr><td></td><td></td><td></td></tr>
<tr><td></td><td></td><td></td></tr>

<tr><td>IC66</td><td>
Yazgi, K., Beyan, C., Mancini, M.,  <b>Niewiadomski, R.</b>, Automatic Recognition of Commensal Activities in Co-located and Online settings. Accepted to International Conference on Multimodal Interaction (ICMI Companion ’24), November 4–8, 2024, San Jose, Costa Rica. ACM, New York, NY, USA, 5 pages, 2024.
<br>
10.1145/3686215.3686219
</td>
<td>
</td>
</tr>

<tr><td>IC65</td><td>
Hoxha, A., Fong, H.,  <b>Niewiadomski, R.</b>, Do We Need Artificial Dining Companions? Exploring Human Attitudes Toward Robots in Commensality Settings. Accepted to International Conference on Multimodal Interaction (ICMI Companion ’24), November 4–8, San Jose, Costa Rica. ACM, New York, NY, USA, 7 pages, 2024.
<br>
10.1145/3686215.3686220
</td>
<td>
</td>
</tr>

<tr><td>IC64</td><td>
Tiuleneva M., Castano E.,  <b>Niewiadomski, R.</b>,
<a href="/papers/ACII24_tiulenevaetal.pdf">How Do We Perceive the Intensity of Facial Expressions? The PIFE Dataset for Analysis of Perceived Intensity</a>, 
In Proceedings of 12th International Conference on Affective Computing and Intelligent Interaction (ACII), September 15-18, Glasgow, UK, 2024, pp. 99-106. 
<br>
</td>
<td>
</td>
</tr>

<tr><td>IC63</td><td>
Chirico, A., Palombi, T., Varni, G.,  <b>Niewiadomski, R.</b>, Li, Y., Lucidi, F., Mancini, M., Fostering Interactive Mindfulness Experiences in VR. In Proceedings of International Conference on eXtended Reality (XR Salento 2024), Lecture Notes in Computer Science, vol 15028. Springer, September 4-7, Lecce, Italy, 2024
<br>
 10.1007/978-3-031-71704-8_15
</td>
<td>
<a href="https://link.springer.com/chapter/10.1007/978-3-031-71704-8_15">[link]</a>
</td>
</tr>

<tr><td>IC62</td><td>
Mancini, M.,  <b>Niewiadomski, R.</b>, De Lucia, G., Longobardi, F.M., 
<a href="/papers/IVA24_mancinietal.pdf">A Virtual Agent as a Commensal Companion</a>,
In Proceedings of ACM International Conference on Intelligent Virtual Agents (IVA ’24), September 16–19, 2024, Glasgow, United Kingdom. ACM, New York, NY, USA, 4 pages, 2024. 
<br>
<i>10.1145/3652988.3673963</i>
</td>
<td>
</td>
</tr>


<tr><td>IC61</td><td>
Tiuleneva, M., Castano, E.,  <b>Niewiadomski, R.</b>, 
<a href="/papers/AVI24_tiulenevaetal.pdf">Towards the dataset for analysis and recognition of facial expressions intensity</a>,
Proceedings of the 2024 International Conference on Advanced Visual Interfaces (AVI '24), 
New York, NY, USA, Article 63, 1–3, 2024,
<br>
<i>10.1145/3656650.3656711</i>
</td>
<td>
<a href="https://doi.org/10.1145/3656650.3656711">[link]</a>
</td>
</tr>


<tr><td>IC60</td><td>
Gulino, C.,  <b>Niewiadomski, R.</b>,
<a href="/papers/AVI24_gulinoetal.pdf">Sounding bodies: Exploring sonification to promote physical contact</a>,
Proceedings of the 2024 International Conference on Advanced Visual Interfaces (AVI '24), 
New York, NY, USA, Article 91, 1–3, 2024,
<br>
<i>10.1145/3656650.3656749</i>
</td>
<td>
<a href="https://doi.org/10.1145/3656650.3656749">[link]</a>
</td>
</tr>


<tr><td>IC59</td><td>
Mancini, M., Chirico, A., <b>Niewiadomski, R.</b>, Varni, G., Palombi, T., Alivernini, F., Lucidi, F., 
<a href="/papers/AVI24_mancinietal.pdf">Multimodal interactive VR mindfulness experience</a>,
Proceedings of the 2024 International Conference on Advanced Visual Interfaces (AVI '24), 
New York, NY, USA, Article 95, 1–3, 2024,
<br>
<i>10.1145/3656650.3656753</i>
</td>
<td>
<a href="https://doi.org/10.1145/3656650.3656753">[link]</a>
</td>
</tr>


<tr><td>IC58</td><td>
Canovi, N., Montagna, F.,  <b>Niewiadomski, R.</b>, Sciutti, A., Di Cesare, G., Beyan, C.,
<a href="https://dl.acm.org/doi/pdf/10.1145/3656650.3656689">
Diffusion-Based Unsupervised Pre-training for Automated Recognition of Vitality Forms</a>,
Proceedings of the 2024 International Conference on Advanced Visual Interfaces (AVI '24), 
New York, NY, USA, Article 34, 1–9, 2024,
<br>
<i>10.1145/3656650.3656689</i>
</td>
<td>
<a href="https://doi.org/10.1145/3656650.3656689">[link]</a>
</td>
</tr>



<tr><td>IC57</td><td>
Mancini, M., Cinelli, M., Etta, G., Ciurla, P., <b>Niewiadomski, R.</b>, Quattrociocchi, W., Franzoni, V., 
Computing Beneficence: a Study of Pro-Social Attitudes in Comments of Online Social Media Users,
2023 11th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos (ACIIW), 
Cambridge, MA, USA, 2023, pp. 1-4, 
<br>
<i>10.1109/ACIIW59127.2023.10388215</i>
</td>
<td>
<a href="https://ieeexplore.ieee.org/abstract/document/10388215">[link]</a>
</td>
</tr>

<tr><td></td><td></td><td></td></tr>


<tr><td>IC56</td><td>
Lechuga Redondo, M.E., Sciutti, A., Rea, F., <b>Niewiadomski, R.</b>,
<a href="/papers/ICMI22_lechugaetal.pdf">Comfortability Recognition from Visual Non-verbal Cues</a>, 
In Proceedings of the 2022 International Conference on Multimodal Interaction (ICMI '22), November 7–11, 2022, Bengaluru, India,  Association for Computing Machinery, New York, NY, USA, 207–216, 2022.
<br>
<i>doi: 10.1145/3536221.3556631</i>
</td>
<td>
<a href="https://dl.acm.org/doi/10.1145/3536221.3556631">[link]</a>
<a href="https://www.youtube.com/watch?v=hdAGFo1qckg">[video 1]</a>
<a href="https://www.youtube.com/watch?v=L7OhMywxmiQ">[video 2]</a>
<a href="/papers/ICMI22_lechugaetal.txt">[bibtex]</a>
</td>
</tr>

<tr><td></td><td></td><td></td></tr>

<tr><td>IC55</td><td>
<b>Niewiadomski, R.</b>, De Lucia, G., Grazzi, G., Mancini, R.,
<a href="/papers/ICMI22_niewiadomskietal.pdf">Towards Commensal Activities Recognition</a>, 
In Proceedings of the 2022 International Conference on Multimodal Interaction (ICMI '22), November 7–11, 2022, Bengaluru, India, Association for Computing Machinery, New York, NY, USA, 549–557, 2022.
<br>
<i>doi: 10.1145/3536221.3556566</i>
</td>
<td>
<a href="https://dl.acm.org/doi/abs/10.1145/3536221.3556566">[link]</a>
<a href="/papers/ICMI22_niewiadomskietal.txt">[bibtex]</a>
<a href="/papers/ICMI22_niewiadomskietal_poster.pdf">[poster]</a>
<a href="https://youtu.be/lQaRx3yGn7I">[video]</a>
</td>
</tr>

<tr><td></td><td></td><td></td></tr>

<tr><td>IC54</td><td>
Ceccaldi, E., De Lucia, G., <b>Niewiadomski, R.</b>, R., Volpe, G., Mancini, M., 
<a href="/papers/AVI22_ceccaldietal.pdf">Social Interaction Data-sets in the Age of Covid-19: a Case Study on Digital Commensality</a>, 
In Proceedings of the 2022 International Conference on Advanced Visual Interfaces (AVI 2022). Association for Computing Machinery, New York, NY, USA, Article 23, 1–5, 2022. 
<br>
<i>doi: 10.1145/3531073.3531176</i>
</td>
<td>
<a href="https://dl.acm.org/doi/10.1145/3531073.3531176">[link]</a>
<a href="/papers/AVI22_ceccaldietal.txt">[bibtex]</a>
</td>
</tr>

<tr><td></td><td></td><td></td></tr>


<tr><td>IC53</td><td>
Lechuga Redondo, M.E., Sciutti, A., Incao, S., Rea, F., <b>Niewiadomski, R.</b>,
<a href="/papers/HRI21_lechugaetal.pdf">Can Robots Impact Human Comfortability During a Live Interview?</a>, 
In Companion of the 2021 ACM/IEEE International Conference on Human-Robot Interaction (HRI '21 Companion). Association for Computing Machinery, New York, NY, USA, 186–189, 2021.
<br>
<i>doi: 10.1145/3434074.3447156</i>
</td>
<td>
<a href="https://dl.acm.org/doi/10.1145/3434074.3447156">[link]</a>
</td>
</tr>

<tr><td></td><td></td><td></td></tr>


<tr><td>IC52</td><td>
<b>Niewiadomski, R.</b>, Sciutti, A., 
<a href="/papers/IUI21_niewiadomskietal.pdf">Multimodal Emotion Recognition of Hand-Object Interaction</a>, 
In 26th International Conference on Intelligent User Interfaces (IUI '21). Association for Computing Machinery, New York, NY, USA, 351–355. 
<b>Honorable Mention Award.</b><br>
<i>doi: 10.1145/3397481.3450636</i>
</td>
<td>
<a href="https://doi.org/10.1145/3397481.3450636">[link]</a>
<br>
<a href="/papers/IUI21_niewiadomskietal.txt">[bibtex]</a>
<a href="https://youtu.be/6bof8KTy6Mc">[video]</a>
</td>
</tr>

<tr><td></td><td></td><td></td></tr>


<tr><td>IC51</td><td>
Gallagher, C.P., <b>Niewiadomski, R.</b>, Bruijnes, M., Huisman, G., Mancini, M., 
<a href="/papers/MH420_gallagheretal.pdf"> Eating with an artificial commensal companion</a>, 
4th Workshop on Multisensory Approaches to Human-Food Interaction, in conjunction with the 22th ACM International Conference on Multimodal Interaction, October 25th, 2020.
<br>
<i>doi: 10.1145/3395035.3425648</i>
</td>
<td>
<a href="https://dl.acm.org/doi/abs/10.1145/3395035.3425648">[link]</a>
<br><a href="/papers/MH420_gallagheretal.txt">[bibtex]</a>
</td>
</tr>

<tr><td></td><td></td><td></td></tr>

<tr><td>IC50</td><td>
Lechuga Redondo, M.E., Vignolo, A., <b>Niewiadomski, R.</b>, Rea, F., Sciutti, A., 
<a href="/papers/ICSR20_lechugaetal.pdf">
Can Robots Elicit Different Comfortability Levels? 
</a>
12th International Conference on Social Robotics (ICSR 2020), Springer, LNAI 12483, November 14-18, 2020.
<br>
<i>doi: 10.1007/978-3-030-62056-1_55</i>
</td>
<td>
<a href="https://link.springer.com/chapter/10.1007%2F978-3-030-62056-1_55">[link]</a>
<br>
</td>
</tr>

<tr><td></td><td></td><td></td></tr>


<tr><td>IC49</td><td>
Mancini, M., Gallagher, C.P., <b>Niewiadomski, R.</b>Huisman, G., Bruijnes, M., 
Introducing Artificial Commensal Companions. International Conference on Advanced Visual Interfaces (AVI’20), September 2020.
<br>
<i>doi: 10.1145/3399715.3399958 </i>
</td>
<td><a href="https://dl.acm.org/doi/abs/10.1145/3399715.3399958">[link]</a>
<br>
</td>
</tr>

<tr><td></td><td></td><td></td></tr>


<tr><td>IC48</td><td>
Mancini, M.,  <b>Niewiadomski, R.</b>, Huisman, G., Bruijnes, M., Gallagher, C.P. 
<a href="/papers/CHI20_mancinietal.pdf">Room for one more? - Introducing Artificial Commensal Companions</a>, In Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems Extended Abstracts (CHI ’20). Association for Computing Machinery, New York, NY, USA, 1–8.
<br>
<i>doi: 10.1145/3334480.3383027 </i>
</td>
<td><a href="/papers/CHI2020_mancinietal.txt">[bibtex]</a>
<br>
</td>
</tr>

<tr><td></td><td></td><td></td></tr>

<tr><td>IC47</td><td>
Bassano, C., Ballestin, G., Ceccaldi, E., Larradet, F., Mancini, M., Volta, E.,  <b>Niewiadomski, R.</b>,  
<a href="/papers/MIG19_bassanoetal.pdf">A VR Game-based System for Multimodal Emotion Data Collection</a>, 
12th annual ACM SIGGRAPH conference on Motion, Interaction and Games 2019 (MIG 2019), October 28-30, 2019, Newcastle Upon Tyne, United Kingdom. 
<br>
<i>doi: 10.1145/3359566.3364695 </i>
</td>
<td><a href="/papers/MIG2019_Bassanoetal.txt">[bibtex]</a>
<br>
<a href="https://dl.acm.org/citation.cfm?id=3359566.3364695">[link]</a>
</td>
</tr>

<tr><td>IC46</td><td>
Larradet, F., <b>Niewiadomski, R.</b>, Barresi, G., Mattos L.S.,   
<a href="/papers/HASCA19_larradetetal.pdf">Appraisal Theory-based Mobile App for Physiological Data Collection and Labelling in the Wild</a>, Seventh International Workshop on Human Activity Sensing Corpus and Applications (HASCA 2019), UbiComp/ISWC ’19 Adjunct, September 9-13, 2019, London, United Kingdom.
<br>
<i>doi: 10.1145/3341162.3345595</i>
</td>

<td><a href="/papers/HASCA2019_larradetetal.txt">[bibtex]</a>
<br>
<a href="https://dl.acm.org/citation.cfm?id=3345595">[link]</a>
<br>
<a href="https://youtu.be/XTWH_VF4vT8">[video]</a>
</td>
</tr>


<tr><td>IC45</td><td>
Volta, E., <b>Niewiadomski, R.</b>, Olugbade, T., Gilio, C., Cocchi, E., Berthouze, N., Gori, M., Volpe, G., 
<a href="/papers/ACII19_voltaetal.pdf">
Analysis of cognitive states during bodily exploration of mathematical concepts in visually impaired children</a>, 
8th International Conference on Affective Computing & Intelligent Interaction (ACII 2019), 3rd-6th September, 2019, Cambridge, United Kingdom
<br>
<i>doi: DOI: 10.1109/ACII.2019.8925521 </i>
</td>
<td><a href="/papers/ACII19_voltaetal.txt">[bibtex]</a>
<br>
<a href="https://ieeexplore.ieee.org/document/8925521">[link]</a>
</td>
</tr>

<tr><td>IC44</td><td>
Karumuri, S., <b>Niewiadomski, R.</b>, Volpe, G., Camurri, A.,  
<a href="/papers/CHI19_karumurietal.pdf">
From Motions to Emotions: Classification of Affect from Dance Movements using Deep Learning</a>,
In Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems (CHI EA '19). ACM, New York, NY, USA, 6 pages. 
<br>
<i>doi: 10.1145/3290607.3312910</i>
</td>
<td><a href="/papers/CHI19_karumurietal.txt">[bibtex]</a>
<br>
<a href="https://dl.acm.org/citation.cfm?id=3312910">[link]</a>
</td>
</tr>

<tr><td>IC43</td><td>
<b>Niewiadomski, R.</b>, Chauvigne, L.,  Mancini, M., Camurri, A., 
<a href ="/papers/MOCO18_niewiadomskietal.pdf">Towards a Model of Nonverbal Leadership in Unstructured Joint Physical Activity</a>, 
Proceedings of the 5th International Conference on Movement and Computing (MOCO 2018), Genoa, Italy, June 28–30, ACM, New York, NY, USA, 2018.
<br>
<i>doi: 10.1145/3212721.3212816</i>
</td>
<td><a href="/papers/MOCO18_niewiadomskietal.txt">[bibtex]</a>
<br>
<a href="https://dl.acm.org/citation.cfm?id=3212816">[link]</a>
</td>
</tr>


<tr><td>IC42</td><td>
<b>Niewiadomski, R.</b>, Mancini, M., Piana, S., Alborno, P., Volpe, G., Camurri, A., 
<a href ="/papers/ICMI17_niewiadomskietal.pdf">Low-Intrusive Recognition of Expressive Movement Qualities</a>, 
Proceedings of the 19th ACM International Conference on Multimodal Interaction (ICMI 2017), Glasgow, UK, November 13–17, ACM, New York, NY, USA, pages 230-237, 2017.
<br>
<i>doi: 10.1145/3136755.3136757</i>
</td>
<td><a href="/papers/ICMI17_niewiadomskietal.txt">[bibtex]</a>
<br>
<a href="https://dl.acm.org/citation.cfm?id=3136757&CFID=830189605">[link]</a>
</td>
</tr>

<tr><td>IC41</td><td>
Alborno, P., Cera, A., Piana, S., Mancini, M., <b>Niewiadomski, R.</b>, Canepa, C., Volpe, G., Camurri, A., Interactive sonification of movement qualities - a case study of fluidity, ISon workshop, Bielefeld, 15-16 December, 2016.
</td><td></td></tr>


<tr>
<td>IC40</td>
<td>
Lussu, V., <b>Niewiadomski, R.</b>. Volpe, G., Camurri, A.,
<a href="/papers/HBU16_lussuetal.pdf">
Using the Audio Respiration Signal for Multimodal Discrimination of Expressive Movement Qualities</a>,
in Proceedings of Human Behavior Understanding: 7th International Workshop, HBU 2016, held in conjunction with ACM Multimedia, Amsterdam, The Netherlands, October 16, 2016, Springer, volume 9997 of the series Lecture Notes in Computer Science, pages 102-115, 2016. <br>
</i>doi: 10.1007/978-3-319-46843-3_7</i>
</td>
<td><a href="/papers/HBU16_lussuetal.txt">[bibtex]</a>
<br>
<a href="http://link.springer.com/chapter/10.1007/978-3-319-46843-3_7">[link]</a></td>
</tr>

<tr><td></td><td></td><td></td></tr>

<tr>
<td>IC39</td>
<td>
Camurri, A., Canepa, C., Ferrari, N., Mancini, M., <b>Niewiadomski, R.</b>, Piana, S., Volpe, G., Matos, J-M., Palacio, P., Romero, M.
<a href="/papers/Body16_camurrietal.pdf">
A system to support the learning of movement qualities in dance: a case study on dynamic symmetry</a>, 
BodySenseUX Workshop held in conjunction with 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing: Adjunct (UbiComp '16),
ACM, New York, NY, USA, pages 973-976, 2016. <br>
<i>doi: 10.1145/2968219.2968261</i>
</td>
<td><a href="/papers/Body16_camurrietal.txt">[bibtex]</a>
<br>
<a href="http://dl.acm.org/citation.cfm?id=2968261">[link]</a></td>
</tr>

<tr><td></td><td></td><td></td></tr>

<tr>
<td>IC38</td>
<td>
Volpe, G., Alborno, P., Camurri, A., Coletta, P., Ghisio, S., Mancini, M., Massari, A., <b>Niewiadomski, R.,</b> Piana, S., Sagoleo, R., 
<a href="http://ceur-ws.org/Vol-1602/paper9.pdf">Designing Multimodal Interactive Systems Using EyesWeb XMI</a>, 
in Proceedings of Smart Ecosystems cReation by Visual dEsign Workshop (SERVE 2016), held in conjunction with AVI 2016.
</td>
<td></td>
</tr>

<tr><td></td><td></td><td></td></tr>

<tr>
<td>IC37</td>
<td>
Piana, S., Coletta, P., Ghisio, S., <b>Niewiadomski, R.</b>, Mancini, M., Sagoleo, R., Volpe, G., Camurri, A., 
<a href="/papers/MOCO16_pianaetal.pdf">
Towards a Multimodal Repository of Expressive Movement Qualities in Dance</a>,
3rd International Symposium on Movement and Computing, MOCO 2016, 5-6 July 2016, Thessaloniki, Greece, 2016.
<br>
<i>doi: 10.1145/2909132.2909262</i>
<td><a href="/papers/MOCO16_piana_et_al.txt">[bibtex]</a>
<br>
<a href="http://dl.acm.org/citation.cfm?id=2948931">[link]</a></td>
</tr>
<tr><td></td><td></td><td></td></tr>

<tr>
<td>IC36</td>
<td>
Camurri, A., Volpe, G., Piana, S., Mancini, M., <b>Niewiadomski</b>, R., Ferrari, N., Canepa, C.,
<a href="/papers/MOCO16_camurrietal.pdf">
The Dancer in the Eye: Towards a Multi-Layered Computational Framework of Qualities in Movement</a>, 
3rd International Symposium on Movement and Computing, MOCO 2016, 5-6 July 2016, Thessaloniki, Greece, 2016. 
<br>
<i>doi: 10.1145/2948910.2948927</i>. 
</td>
<td><a href="/papers/MOCO16_camurri_et_al.txt">[bibtex]</a>
<br>
<a href="http://dl.acm.org/citation.cfm?id=2948927">[link]</a></td>
</tr>
<tr><td></td><td></td><td></td></tr>

<tr>
<td>IC35</td>
<td>
Alborno, P., Piana, S., Mancini, M., <b>Niewiadomski, R.,</b> Volpe, G., Camurri, A., <a href="/papers/AVI16_albornoetal.pdf"> Analysis of Intrapersonal Synchronization in Full-Body Movements Displaying Different Expressive Qualities</a>, in Proceedings of the International Working Conference on Advanced Visual Interfaces (AVI '16), Paolo Buono, Rosa Lanzilotti, and Maristella Matera (eds.), ACM, New York, NY, USA, pages 136-143, 2016. <br>
<i>doi: 10.1145/2909132.2909262</i> 
</td>
<td>
<a href="/papers/AVI_2016_albornoetal.txt">[bibtex]</a>
<br>
<a href="http://dl.acm.org/citation.cfm?doid=2909132.2909262">[link]</a></td>
</tr>
<tr><td></td><td></td><td></td></tr>

<tr>
<td>IC34</td>
<td>
Piana, S., Alborno, P., <b>Niewiadomski, R.,</b> Mancini, M., Volpe, G., Camurri, A, 
<a href="/papers/CHI16_pianaetal.pdf"> 
Movement Fluidity Analysis Based on Performance and Perception</a>, In Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems (CHI EA '16), ACM, New York, NY, USA, pages 1629-1636, 2016.
<br>
<i>doi: 10.1145/2851581.2892478</i> 
</td>
<td>
<a href="/papers/CHI16_pianaetal.txt">[bibtex]</a>
<br>
<a href="http://dl.acm.org/citation.cfm?doid=2851581.2892478">[link]</a></td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>

<tr>
<td>IC33</td>
<td>
<b>Niewiadomski, R.</b>, Mancini, M., Volpe, G., Camurri, A., <a href="/papers/CHItaly15_niewiadomskietal.pdf"> Automated Detection of Impulsive  Movements in  HCI</a>, CHItaly 2015: the 11th biannual  Conference  of  the  Italian  SIGCHI  Chapter, ACM, New York, NY, USA, 166-169, 2015.
<br>
<i>doi: 10.1145/2808435.2808466</i> 
</td>
<td><a href="/papers/CHItaly15_niewiadomskietal.txt">[bibtex]</a>
<br>
<a href="http://dl.acm.org/citation.cfm?id=2808466">[link]</a></td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>


<td>IC32</td>
<td>
<b>Niewiadomski, R,</b> Ding, Y., Mancini, M., Pelachaud, C., Volpe, G., Camurri, A., 
<a href="/papers/ACII15_niewiadomskietal.pdf">Perception of intensity incongruence in synthesized multimodal expressions of laughter</a>, Affective Computing and Intelligent Interaction (ACII), 2015 International Conference on, Xi'an, pages 684-690, 2015.
<br>
<i>doi: 10.1109/ACII.2015.7344643</i>
</td>
<td><a href="/papers/ACII15_niewiadomskietal.txt">[bibtex]</a>
<br>
<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7344643">[link]</a></td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>IC31</td>
<td>
Kolykhalova, K., Camurri, A., Volpe, G., Sanguineti, M., Puppo, E., <b>Niewiadomski, R.</b>, <a href="/papers/INTETAIN15_kolykhalovaetal.pdf">A Multimodal Dataset for the Analysis of Movement Qualities in Karate Martial Art</a>, in Intelligent Technologies for Interactive Entertainment (INTETAIN),  7th International Conference on, Turin, pages 74-78, 2015.
<br>
<i>doi: 10.4108/icst.intetain.2015.260039</i>
</td>
<td><a href="/papers/INTETAIN15_kolykhalova_etal.txt">[bibtex]</a>
<br>
<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7325489">[link]</a></td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>IC30</td>
<td>
<b>Niewiadomski, R.</b>, Mancini, M. Ding, Y., Pelachaud, C., Volpe, G., <a href="/papers/ICMI14_niewiadomskietal.pdf">Rhythmic body movements of laughter</a>,
in Proceedings of the 16th International Conference on Multimodal Interaction (ICMI '14), ACM, New York, NY, USA, pages 299-306, 2014. 
<br>
<i>doi: 10.1145/2663204.2663240</i>
</td>
<td>
<a href="/papers/ICMI14_niewiadomskietal.txt">[bibtex]</a>
<br>
<a href="http://dl.acm.org/citation.cfm?doid=2663204.2663240">[link]</a>
</td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>IC29</td>
<td>
Mancini, M., Varni, G., <b>Niewiadomski, R.</b>, Volpe, G., Camurri, A., <a href="/papers/CHI14_mancinietal.pdf"> How is your laugh today?</a>, in CHI '14 Extended Abstracts on Human Factors in Computing Systems (CHI EA '14). ACM, New York, NY, USA, pages 1855-1860, 2014.
<br><i>doi: 10.1145/2559206.2581205</i> 
</td>
<td>
<a href="/papers/CHI14_mancinietal.txt">[bibtex]</a>
<br>
<a href="http://doi.acm.org/10.1145/2559206.2581205">[link]</a>
</td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>IC28</td>
<td>
<b>Niewiadomski, R.</b>, Mancini, M., Baur, T., Varni, G., Griffin, H., Aung, M.S.H., 
<a href="/papers/HBU13_niewiadomskietal.pdf"> MMLI: Multimodal Multiperson Corpus of Laughter in Interaction</a>,
in Proceedings of Fourth International Workshop on Human Behavior Understanding (HBU 2013), in conjunction with ACM Multimedia'2013, 
Lecture Notes in Computer Science 8212, Springer International 
Publishing, pages 184-195, Barcelona, Spain, 2013. 
<br><i>doi: 10.1007/978-3-319-02714-2_16</i>
</td>
<td>
<a href="/papers/HBU13_niewiadomskietal.txt">[bibtex]</a>
<br>
<a href="http://link.springer.com/chapter/10.1007%2F978-3-319-02714-2_16">[link]</a>
</td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>IC27</td>
<td>
Urbain, J., <b>Niewiadomski, R.</b>, Mancini, M., Griffin, H., Cakmak, H., Ach, L. Volpe, G., Multimodal Analysis of laughter for an Interactive 
System, in Proceedings of INTETAIN 2013, Lecture Notes of the Institute for Computer Sciences, Social Informatics
 and Telecommunications Engineering, Volume 124, pages 183-192 Mons, Belgium, 2013.
<br>
doi: 10.1007/978-3-319-03892-6_22
</td>
<td>
<a href="/papers/INTETAIN2013_urbainetal.txt">[bibtex]</a>
<br>
<a href="http://link.springer.com/chapter/10.1007%2F978-3-319-03892-6_22">[link]</a>
</td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>IC26</td>
<td>
<b>Niewiadomski, R.</b>, Hofmann, J., Urbain, J., Platt, T., Wagner, J., Piot, 
B., Cakmak, H., Pammi, S., Baur, T., Dupont, S., Geist, M., 
Lingenfelser, F., McKeown, G., Pietquin, O., Ruch, W., <a href="http://www.ifaamas.org/Proceedings/aamas2013/docs/p619.pdf">Laugh-aware virtual agent and its impact on user amusement</a>, International Conference on Autonomous Agents and Multiagent Systems, 
AAMAS 2013, International Foundation for Autonomous Agents and 
Multiagent Systems, pages 619-626, Saint Paul, Minnessota, USA, 2013. 
<br> <i> doi: 10.13140/2.1.1984.0960 </i>
</td>
<td>
<a href="/papers/AAMAS13_niewiadomskietal.txt">[bibtex]</a>
<br>
</td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>IC25</td>
<td>
<b>Niewiadomski, R.</b>, Pammi, S., Sharma, A., Hofmann, J., Platt, T., Cruz, 
R.T., Qu, B., Visual laughter synthesis: Initial approaches, 
Interdisciplinary Workshop on Laughter and other Non-Verbal 
Vocalisations in Speech, Dublin, Ireland, October 2012.
</td>
<td>
</td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>IC24</td>
<td>
Qu, B., Pammi, S., <b>Niewiadomski, R.</b>, Chollet, G., Estimation of FAPs and
 intensities of AUs based on real-time face tracking, FAA'12, The 3rd 
International Symposium on Facial Analysis and Animation, Vienna, 
September 2012.
<br>
<i>doi: 10.1145/2491599.2491612</i>
</td>
<td>
<a href="https://dl.acm.org/citation.cfm?doid=2491599.2491612">[link]</a>
</td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>IC23</td>
<td>
<b>Niewiadomski, R.</b>, Pelachaud, C., <a href="/papers/IVA12_niewiadomskietal.pdf">Towards Multimodal Expression of Laughter</a>,
 Proceedings of the 12th International Conference on Intelligent Virtual Agents (IVA 2012), Santa Cruz, USA, pages 231–244, 2012.
<br>
<i>doi: 10.1007/978-3-642-33197-8_24</i>
</td>
<td>
<a href="/papers/IVA2012_niewiadomskietal.txt">[bibtex]</a>
<br>
<a href="http://link.springer.com/chapter/10.1007/978-3-642-33197-8_24">[link]</a>
</td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>IC22</td>
<td>
<b>Niewiadomski, R.</b>, Huang, J., Pelachaud, C., <a href="/papers/CASA12_niewiadomskietal.pdf">Effect of Facial Cues on Identification</a>, Proceedings of the 25th Annual Conference on Computer Animation and Social Agents (CASA 2012), Singapore, 2012.
</td>
<td>
</td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>IC21</td>
<td>
<b>Niewiadomski, R.</b>, Urbain, J., Pelachaud, C., Dutoit, T., <a href="/papers/LREC12_niewiadomskietal.pdf">Finding
 out the audio and visual features that influence the perception of laughter intensity and differ in inhalation and exhalation phases</a>, 
ES³ 2012 4th International Workshop on Corpora for Research on Emotion, 
Sentiment &amp; Social Signals, LREC 2012, European Language Resources Association (ELRA), Istanbul, Turkey, pages 25-31, 2012.
</td>
<td>
</td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>IC20</td>
<td>
Obaid, M., <b>Niewiadomski, R.</b>, Pelachaud, C., <a href="/papers/IVA11_obaidetal.pdf">Perception of Spatial Relations and of Coexistence with Virtual Agents</a>, Proceedings of the 11th International Conference on Intelligent Virtual Agents, Reykjavík, Iceland, pages 363-369, 2011.
<br>
<i>doi: 10.1007/978-3-642-23974-8_39</i>
</td>
<td>
<a href="/papers/IVA11_obaidetal.txt">[bibtex]</a>
<br>
<a href="http://link.springer.com/chapter/10.1007%2F978-3-642-23974-8_39">[link]</a>
</td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>IC19</td>
<td>
<b>Niewiadomski, R.</b>, Bevacqua, E., Quoc Anh Le, Obaid, M., Looser, J., Pelachaud, C., 
<a href="/papers/WEB3D11_niewiadomskietal.pdf">Cross-media agent platform</a>, 2011 Web3D ACM Conference, Paris, France, pages 11-19, 2011.
<br>
<i>doi: 10.1145/2010425.2010428</i>
</td>
<td>
<a href="/papers/WEB3D11_niewiadomskietal.txt">[bibtex]</a>
<br>
<a href="http://dl.acm.org/citation.cfm?id=2010428">[link]</a>
</td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>IC18</td>
<td>
<b>Niewiadomski, R.</b>, Prepin, K., Bevacqua, E., Ochs, M., Pelachaud, C., 
<a href="/papers/SSPW10_niewiadomskietal.pdf">Towards a smiling ECA: Studies on mimicry, timing and types of smiles</a>,
 ACM Multimedia 2010 Social Signal Processing Workshop (SSPW 2010), ACM, New York, NY, USA, Firenze, Italy, pages 65-70, 2010.
<br>
<i>doi: 10.1145/1878116.1878134</i>
</td>
<td>
<a href="/papers/sspw2010_niewiadomskietal.txt">[bibtex]</a>
<br>
<a href="http://dl.acm.org/citation.cfm?id=1878134">[link]</a>
</td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>IC17</td>
<td>
<b>Niewiadomski, R.</b>, Demeure, V., Pelachaud, C., <a href="/papers/IVA10_niewiadomskietal.pdf">Warmth, Competence, Believability and Virtual Agents</a>, in Proceedings of the 10th International Conference on Intelligent Virtual Agents, Philadelphia, USA, pages 272-285, 2010. 
<b>Best Paper Award</b>. 
<br>
<i>doi: 10.1007/978-3-642-15892-6_29</i>
</td>
<td>
<a href="/papers/IVA10_niewiadomskietal.txt">[bibtex]</a>
<br>
<a href="http://link.springer.com/chapter/10.1007%2F978-3-642-15892-6_29">[link]</a>
</td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>IC16</td>
<td>
Ochs, M., <b>Niewiadomski, R.</b>, Pelachaud, C., <a href="/papers/IVA10_ochsetal.pdf">
How a Virtual Agent Should Smile? - Morphological and Dynamic Characteristics of Virtual Agent's Smiles</a>, 
in Proceedings of the 10th International Conference on Intelligent Virtual Agents, Philadelphia, USA, pages 427-440, 2010.
<br>
<i>doi: 10.1007/978-3-642-15892-6_47</i>
</td>
<td>
<a href="/papers/IVA10_ochsetal.txt">[bibtex]</a>
<br>
<a href="http://link.springer.com/chapter/10.1007%2F978-3-642-15892-6_47">[link]</a>
</td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>IC15</td>
<td>
Urbain J., Bevacqua E., Dutoit T., Moinet A., <b>Niewiadomski, R.</b>, Pelachaud C., Picart B., Tilmanne J., Wagner J.,
The AVLaughterCycle database, in Proceedings of The seventh international conference on Language Resources and Evaluation
LREC 2010, Malta, pages 2996-3001, 2010.
</td>
<td>
</td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>IC14</td>
<td>
<b>Niewiadomski, R.</b>, Hyniewska S., Pelachaud C., Introducing Multimodal Sequential Emotional Expressions For Virtual Characters, 
International Conference On Kansei Engineering And Emotion Research 2010, pages 1041-1050, Paris, France, 2010.
</td>
<td>
</td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>IC13</td>
<td>
Bleackley P., Hyniewska S., <b>Niewiadomski, R.</b>,  Pelachaud C., Price M., <a href="/papers/KEER10_bleackleyetal.pdf">Emotional Interactive Storyteller System</a>,
International Conference On Kansei Engineering And Emotion Research 2010, pages 1716-1726, Paris, France, 2010.
</td>
<td></td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>IC12</td>
<td>
<b>Niewiadomski, R.</b>, Hyniewska, S., Pelachaud, C., <a href="/papers/ACII09_niewiadomskietal.pdf">Evaluation of Multimodal Sequential Expressions of Emotions in ECA</a>, in Proceedings of Third International Conference on Affective 
Computing and Intelligent Interaction (ACII 2009), Amsterdam, Holland,  pages 635-641, 2009.
<br>
<i>doi: 10.1109/ACII.2009.5349569</i>
</td>
<td>
<a href="/papers/ACII09_niewiadomskietal.txt">[bibtex]</a>
<br>
<a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5349569&tag=1">[link]</a>
</td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>IC11</td>
<td>
<b>Niewiadomski, R.</b>, Hyniewska, S., Pelachaud, C., <a href="/papers/IVA09_niewiadomskietal.pdf">Modeling emotional expressions as sequences of behaviors</a>, in Proceedings of the 9th International Conference on Intelligent Virtual Agents, Amsterdam, Holland, pages 316-322, 2009.
<br>
<i>10.1007/978-3-642-04380-2_34</i>
</td>
<td>
<a href="/papers/IVA09_niewiadomskietal.txt">[bibtex]</a>
<br>
<a href="http://link.springer.com/chapter/10.1007%2F978-3-642-04380-2_34">[link]</a>
</td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>IC10</td>
<td>
<b>Niewiadomski, R.</b>, Bevacqua, E., Mancini, M., Pelachaud, C., 
<a href="http://www.ifaamas.org/Proceedings/aamas09/pdf/06_Demos/d_15.pdf">Greta: an interactive expressive ECA system</a>, 
in Proceedings of the Eighth International Conference on Autonomous Agents and Multiagent Systems, 
Budapest, pages 1399-1400, 2009.
<td>
<a href="/papers/AAMAS09_niewiadomskietal.txt">[bibtex]</a>
</td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>IC9</td>
<td>
Urbain, J., Dupont, S., Dutoit, T., <b>Niewiadomski, R.</b>, Pelachaud, C.,
Towards a virtual agent using similarity-based laughter production, 
Interdisciplinary Workshop on Laughter and other Interactional Vocalisations in Speech, Berlin,
February 27-28, 2009.
</td>
<td></td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>IC8</td>
<td>
<b>Niewiadomski, R.</b>, Ochs, S., Pelachaud, C., <a href="/papers/IVA08_niewiadomskietal.pdf">Expressions of empathy in ECAs</a>, in
Proceedings of the 8th International Conference on Intelligent Virtual Agents, Tokyo, Japan, pages 37-44, 2008.
<br>
<i>10.1007/978-3-540-85483-8_4</i>
</td>
<td><a href="/papers/IVA08_niewiadomskietal.txt">[bibtex]</a>
<br>
<a href="http://link.springer.com/chapter/10.1007%2F978-3-540-85483-8_4">[link]</a>
</td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>IC7</td>
<td>
<b>Niewiadomski, R.</b>, Pelachaud, C., <a href="/papers/IVA07_niewiadomskietal.pdf">Fuzzy Similarity of Facial Expressions of Embodied
Agents</a>, in Proceedings of the 7th International Conference on Intelligent Virtual Agents, Paris, France, pages 86-98, 2007.
<br>
<i>10.1007/978-3-540-74997-4_9</i>
</td>
<td><a href="/papers/IVA07_niewiadomskietal.txt">[bibtex]</a>
<br>
<a href="http://link.springer.com/chapter/10.1007%2F978-3-540-74997-4_9">[link]</a>
</td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>IC6</td>
<td>
<b>Niewiadomski, R.</b>, Pelachaud, C., <a href="/papers/ACII07_niewiadomskietal.pdf">Model of Facial Expressions Management for an Embodied
Conversational Agent</a>, in Proceedings of Second International
Conference on Affective Computing and Intelligent Interaction
(ACII’2007), Lisbon, Portugal, pages 12-23, 2007.
<br>
<i>10.1007/978-3-540-74889-2_2</i>
</td>
<td><a href="/papers/ACII07_niewiadomskietal.txt">[bibtex]</a>
<br>
<a href="http://link.springer.com/chapter/10.1007%2F978-3-540-74889-2_2">[link]</a>
</td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>IC5</td>
<td>
Bevacqua, E., Mancini, M., <b>Niewiadomski, R.</b>, Pelachaud, C., 
<a href="/papers/AISB06_bevacquaetal.pdf">An expressive ECA showing complex emotions</a>, 
in Proceedings of the AISB Annual Convention,
Newcastle, UK, pages 208-216, 2007.
</td>
<td></td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>IC4</td>
<td>
Buisine, S., Abrilian, S., <b>Niewiadomski, R.</b>, Martin, J.-C., Devillers, 
L., Pelachaud, C., 
<a href="/papers/IVA06_buisineetal.pdf">Perception of Blended Emotions: From Video Corpus to Expressive Agent</a>,
in Proceedings of the 6th International Conference on
 Intelligent Virtual Agents, Marina del Rey, pages 93-106, August 2006. 
<b>Best Paper Award</b>.
<br>

<i>doi: 10.1007/11821830_8</i>
</td>
<td>
<a href="/papers/IVA06_buisine_etal.txt">[bibtex]</a>
<br>
<a href="http://link.springer.com/chapter/10.1007%2F11821830_8">[link]</a>
</td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>IC3</td>
<td>
Ochs, M., <b>Niewiadomski, R.</b>, Pelachaud, C., Sadek, D., <a href="/papers/ACII05_ochsetal.pdf">Intelligent Expressions of Emotions</a>, in Proceedings of the
1st International Conference on Affective Computing and Intelligent
Interaction ACII, China, pages 707-714, October 2005.
<br>
<i>https://doi.org/10.1007/11573548_91</i>
</td>
<td>
<a href="/papers/ACII05_ochsetal.txt">[bibtex]</a>
<br>
<a href="https://link.springer.com/chapter/10.1007/11573548_91">[link]</a>
</td>
</tr>
<tr><td></td><td></td><td></td></tr>


<tr>
<td>IC2</td>
<td>
Milani, A., Morici, C., <b>Niewiadomski, R.</b>, Fuzzy Matching of User Profiles for a Banner
Engine, Proceeding of the ICCSA 2004, May 14-17, Assisi, Italy, pages 433-442, 2004.
<br>
doi: 10.1007/978-3-540-24767-8_45 
</td>
<td>
</td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>IC1</td>
<td>
Morici, C., <b>Niewiadomski, R.</b>, A framework for a personalized advertising on
Web based on maximal fuzzy similarity in Lukasiewicz structure,
Proceedings of the Tenth International Conference on Information
Processing and Management of Uncertainty - IPMU 2004, July 4-9, pages 433-442, 2004.
</td>
<td>
</td>
</tr>
</table>
<br><br><br>
<b><a name="nconference">National Conference and Workshop Papers:</a></b>
<br><br>
<table border=0>
<tr VALIGN="top">
<td>NC5</td>
<td>
Ochs, M., Bevacqua, E., Prepin, K.,  Le, Q.A., Ding, Y., Huang, J.-F., <b>Niewiadomski, R.</b> Pelachaud, C., La compréhension de la machine à travers
 l'expression non-verbale, III : Intercompréhension - de l'intraspécifique à l'interspécifique, Nantes, France, November 2011.
</td>
<td>
</td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>NC4</td>
<td>
Urbain J., Bevacqua E., Dutoit T., Moinet A., <b>Niewiadomski, R.</b>, Pelachaud C., Picart B., Tilmanne J., Wagner J.
La base de donnees AVLaughterCycle, Les Journees d'Etude sur la Parole (JEP2010), Mons, pages 61-64, 2010.
</td>
<td></td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>NC3</td>
<td>
Mancini, M., <b>Niewiadomski, R.</b>, Bevacqua, E., Pelachaud., C. Greta: a SAIBA compliant ECA 
system, in: Troisiéme Workshop sur les Agents Conversationnels Animés WACA 08, Paris, France, 27-28 
November 2008.
</td>
<td></td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>NC2</td>
<td>
<b>Niewiadomski, R.</b>, Ochs, M., Pelachaud, C., Using facial expressions to display empathy in ECAs. 
In Speech and Face to Face Communication Workshop, Grenoble, France, 27-29 October 2008.
</td>
<td></td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>NC1</td>
<td>
Buisine, S., <b>Niewiadomski, R.</b>, Martin, JC., Devillers, L., Pelachaud, C.,
Perception d'Emotions Mélangées : Du Corpus Vidéo à l'Agent Expressif,  in Workshop sur les Agents Conversationnels Animés WACA 06, Toulouse, France, 2006.
</td>
<td></td>
</tr>
</table>
<br><br><br>
<b><a name="others">Others:</a></b>
<br><br>
<table border=0>

<tr VALIGN="top">
<td>O6</td>
<td>
Urbain, J, <b>Niewiadomski, R.</b>, Hofmann, J., Bantegnie, E., Baur, T., 
Berthouze, B.,  Cakmak, H., Cruz, T., Dupont, S., Geist, M., Griffin, 
H., Lingenfelser, F., Mancini, M., Miranda, M., Mckeown, G., Pammi, S., 
Pietquin, O., Piot, B., Platt, T., Ruch, W., Sharma, A., Volpe, G., 
Wagner, J., Proceedings of the 8th International Summer Workshop on 
Multimodal Interfaces, eNTERFACE 12, Metz, France, 2012.
</td>
<td>
</td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>O5</td>
<td>
Chauveau, L., <b>Niewiadomski, R.</b>, Pelachaud, C., Animation faciale de séquences de rire pour des ACAs,
journée de travail "Agents Conversationnels Animés", Paris, France, 22 November, 2011.
</td>
<td>
</td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>O4</td>
<td>
Pelachaud C., <b>Niewiadomski, R.</b>, Ochs M., Introducing Greta: a real-time three dimensional embodied conversational agent,
7tH International Conference of Hands on! Paris, France, 3-6 November, 2009.
</td>
<td>
</td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>O3</td>
<td>
Urbain, J., Bevacqua, E., Dutoit, T., Moinet, A., <b>Niewiadomski, R.</b>, 
Pelachaud, C., Picart, B., Tilmanne, J., Wagner, J., 
AVLaughterCycle: An audiovisual laughing machine, Proceedings of the 5th
 International Summer School on Multimodal Interfaces, eNTERFACE 09, 
Genoa, Italy, 2009.
</td>
<td>
</td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>O2</td>
<td>Bevacqua, E., Prepin, K., de Sevin, E., <b>Niewiadomski, R.</b>, Pelachaud, C.,
Reactive behaviors in SAIBA architecture, in Proceedings of Towards a Standard Markup Language for Embodied Dialogue Acts Workshop held in conjunction with AAMAS 2009,
Budapest, Hungary, 2009.
</td>
<td>
</td>
</tr>
<tr><td></td><td></td><td></td></tr>
<tr>
<td>O1</td>
<td>
<b>Niewiadomski, R.</b>, Ochs, M., Pelachaud, C., Sadek, D., Social Context Based Emotion Expression, 
3rd HUMAINE EU Summer School, Casa Paganini-InfoMus Lab, DIST, University of Genoa, 
Italy, September 2006.
</td>
<td>
</td>
</tr>
</table>

</div>
</div></body></html>