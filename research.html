<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html><head>

 
  <title>Research</title>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <link rel="stylesheet" type="text/css" href="style.css" media="screen">
  <meta name="robots" content="follow,index">  
 </head><body>


<div id="container">
<div id="navcontainer">
<ul id="navlist">
<li><a href="index.html">Home</a></li>
<li><a href="research.html">Research</a></li>
<li><a href="papers.html">Publications</a></li>
<li><a href="others.html">Datasets</a></li>
</ul>
</div>
   

<table border=0>
<tr VALIGN="top">
<td>
My research interests are related to Affective and Social Computing. In my work, I model complex dynamic phenomena such as nonverbal emotional communication and social relations, applying these models to create emotionally intelligent interactive systems capable of understanding human nonverbal behavior.
<br> 
<br> 
The way I conduct research is characterized by strong interdisciplinarity: I apply state-of-the-art methods in Artificial Intelligence, such as soft computing and machine learning, and collaborate closely with psychologists. My work often originates from findings in the human sciences (e.g., annotations of expressive behaviors, theoretical models, emotion elicitation protocols) and models them using machine/deep learning methods.
<br> 
<br> 
They have diverse application areas, including social skills training, the development of socially intelligent artificial assistants and companions (e.g., for elderly people), therapy and rehabilitation, social inclusion (e.g., for autistic and visually impaired individuals), entertainment (e.g., video games), and, more generally, the creation of interactive systems.
<br>	
</td>
</tr>
</table>
 
<BR><BR>

<H1>Emotion Recognition</H1>

Significant effort has been made over the last two decades in the field of automatic emotion recognition from nonverbal signals. The main focus has been on visual cues (e.g., full-body movements, facial expressions) and audio cues (e.g., prosody), while other modalities have been rarely investigated. Most works focus on the recognition of the six basic emotions, although the models are still often trained on datasets collected with limited ecological validity.

In this area, our interests are multiple. First, we aim to develop innovative methods and protocols for multimodal data collection. This includes a variety of sensors and modalities (e.g., affective touch (ref,ref), emotion detection from audio of respriation(ref)) but especially novel procedures for inducing emotions in laboratory settings, as well as collecting data in the field (ref). Examples of such approaches include using an artificial agent as a confederate (ref) and manipulating events in virtual reality (ref). Second, we are interested in the complexity of emotional expressions, including individual differences in affective reactions, the role of context, as well as emotion regulation. Our goal is to move away from the dominant Ekmanian approach, which has strongly influenced both research and commercial solutions in this field, toward a deeper and more nuanced perspective that accounts for the variety of meanings and subtle differences in affective reactions. This requires new techniques of data collection that allows for to collect reach contextual information.

<H1>Positive Computing</H1>

Positive psychology aims to improve well-being and strengthen positive attitudes. It proposes tools and methods that foster individual well-being by enhancing positive feelings, positive thoughts, and positive behaviors. At the same time, researchers have begun to investigate positive emotions more broadly, identifying at least 20 distinct positive emotional states, many of which are associated with specific expressive behaviors or physiological changes.
In this context, we are particularly interested in analyzing specific positive emotional states and classifying them from nonverbal cues (ref). Among others, we studied smiles and laughter in various contexts and meanings—for example, distinguishing their positive versus negative social or emotional functions (ref). We also proposed methods for detecting laughter from body movements,we developed interactive laughter-aware agents (ref) and created multiple relavant datasets for the research community (ref, ref).
Currently we shift toward recognizing a wider range of positive emotions and exploring applications of this technology for enhancing well-being, in line with the concept of positive computing—a rapidly emerging trend in HCI that aims to design and evaluate technologies supporting psychological well-being, human flourishing, and positive user experiences.


<H1>Multimodal Interactions with Artificial Agents</H1>

Artificial agents, such as virtual autonomous characters and social robots, are becoming increasingly present in daily life, entering various domains—from commerce and healthcare to education and entertainment. It is crucial that they are able to create natural, human-like interactions, including appropriate nonverbal communication. This encompasses the expression of affective and cognitive states, social attitudes, and interpersonal relations. 
In this line of research, we have worked, among other topics, on perceived believability, warmth, and competence, and more recently on social comfort. We have developed agents that nonverbally display empathy, deception, politeness, and various other social attitudes. Our current focus is on the applicative dimension, particularly on developing artificial commensal companions. The commensality can be considered a valuable testbed for development of Social Artificial Agents, as it involves rich and complex interactions, including shared attention, unstructured verbal communication, interpersonal synchronization, and a wide variety of emotions.

<H1>Human Behavior Understanding</H1>

More details about selected works can be found <a href="research_old.html">here</a>.

<br><br>

</div></body></html>